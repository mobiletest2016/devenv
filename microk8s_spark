Install:
	sudo snap install microk8s --classic

Configure your firewall to allow pod-to-pod and pod-to-internet communication:
	sudo ufw allow in on cni0 && sudo ufw allow out on cni0
	sudo ufw default allow routed

Start/Stop/Status:
	microk8s start
	microk8s status
	microk8s stop

Enable addons:
	microk8s enable dns 
	microk8s enable storage
	microk8s enable dashboard
	microk8s enable helm
	microk8s enable helm3

Dashboard:
	microk8s kubectl get all --all-namespaces
 
 
 kube-system   service/kubernetes-dashboard        ClusterIP   10.152.183.76    <none>        443/TCP                  8d

Visit from browser: 10.152.183.76:443

Token for dashboard:
	microk8s kubectl describe secret -n kube-system microk8s-dashboard-token
	OR
	token=$(microk8s kubectl -n kube-system get secret | grep default-token | cut -d " " -f1)
	microk8s kubectl -n kube-system describe secret $token

Deploy microbot: 
	microk8s kubectl create deployment microbot --image=dontrebootme/microbot:v1
	microk8s kubectl scale deployment microbot --replicas=2
	microk8s kubectl expose deployment microbot --type=NodePort --port=80 --name=microbot-service
	microk8s kubectl get all --all-namespaces

default       service/microbot-service            NodePort    10.152.183.70    <none>        80:30527/TCP             8d


Visit from browser: 10.152.183.70


Run Spark on microk8s:


https://nvidia.github.io/spark-rapids/docs/dev/microk8s.html
https://www.waitingforcode.com/apache-spark/setting-up-apache-spark-kubernetes-microk8s/read
https://chapeau.freevariable.com/2021/04/microk8s.html


sudo docker pull apache/spark


microk8s.kubectl create serviceaccount spark
microk8s.kubectl create rolebinding spark-role --clusterrole=cluster-admin --serviceaccount=default:spark-editor	(Tried this due to error)


microk8s kubectl create token default

token=(value from above)


Add to /etc/hosts:
127.0.0.1 kubernetes.default.svc.cluster.local


(Find out location spark-examples_*.jar in docker container)
sudo docker run -it apache/spark /bin/bash
find / -name *example*jar
(Found /opt/spark/examples/jars/spark-examples_2.12-3.4.1.jar)

Run:
bin/spark-submit     --master k8s://https://kubernetes.default.svc.cluster.local:16443     --deploy-mode cluster --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark     --conf spark.kubernetes.authenticate.caCertFile=/var/snap/microk8s/current/certs/ca.crt --conf spark.kubernetes.authenticate.submission.caCertFile=/var/snap/microk8s/current/certs/ca.crt     --conf spark.kubernetes.authenticate.submission.oauthToken=$token     --conf spark.kubernetes.container.image=apache/spark --conf spark.executor.instances=2 --conf spark.kubernetes.file.upload.path='/tmp/' --class org.apache.spark.examples.SparkPi  local:///opt/spark/examples/jars/spark-examples_2.12-3.4.1.jar

On another console run:
$ microk8s.kubectl get pods
NAME                                                        READY   STATUS      RESTARTS        AGE
org-apache-spark-examples-sparkpi-5b04d98a22136958-driver   1/1     Running     0               13s
spark-pi-ed223e8a22138397-exec-1                            1/1     Running     0               5s
spark-pi-ed223e8a22138397-exec-2                            1/1     Running     0               5s
